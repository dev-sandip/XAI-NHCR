{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently using cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg \n",
    "import torch \n",
    "import torchvision \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms,models\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "import os \n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             ConfusionMatrixDisplay)\n",
    "import PIL\n",
    "from PIL import Image\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import cv2\n",
    "from captum.insights import AttributionVisualizer, Batch\n",
    "from captum.insights.attr_vis.features import ImageFeature\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"currently using {device}\")\n",
    "\n",
    "img_transforms = v2.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "index_to_targets = {0: 'अ', 1: 'अं', 2: 'अः', 3: 'आ', 4: 'इ', 5: 'ई', 6: 'उ', 7: 'ऊ', 8: 'ए', 9: 'ऐ', 10: 'ओ', 11: 'औ', 12: 'क', 13: 'क्ष', 14: 'ख', 15: 'ग', 16: 'घ', 17: 'ङ', 18: 'च', 19: 'छ', 20: 'ज', 21: 'ज्ञ', 22: 'झ', 23: 'ञ', 24: 'ट', 25: 'ठ', 26: 'ड', 27: 'ढ', 28: 'ण', 29: 'त', 30: 'त्र', 31: 'थ', 32: 'द', 33: 'ध', 34: 'न', 35: 'प', 36: 'फ', 37: 'ब', 38: 'भ', 39: 'म', 40: 'य', 41: 'र', 42: 'ल', 43: 'व', 44: 'श', 45: 'ष', 46: 'स', 47: 'ह', 48: '०', 49: '१', 50: '२', 51: '३', 52: '४', 53: '५', 54: '६', 55: '७', 56: '८', 57: '९'}\n",
    "\n",
    "model_state_path = \"/home/pujan/D/projects/minor project/res97_state.pth\"\n",
    "\n",
    "model = models.resnet101(pretrained=True).to(device)\n",
    "num_classes = 58\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_state_path,map_location=device))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "img_transform = v2.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28,28)),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "test_image_path = Path(\"/home/pujan/D/datasets/nepali_augmented/nhcd_pytorch/test\")\n",
    "test_data = datasets.ImageFolder(root= test_image_path,\n",
    "                                 transform= img_transforms)\n",
    "def get_classes():\n",
    "    classes = test_data.classes\n",
    "    return classes\n",
    "\n",
    "def baseline_func(input):\n",
    "    return input * 0\n",
    "\n",
    "\n",
    "def formatted_data_iter():\n",
    "    dataloader = iter(\n",
    "        torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)\n",
    "    )\n",
    "    while True:\n",
    "        images, labels = next(dataloader)\n",
    "        yield Batch(inputs=images, labels=labels)\n",
    "\n",
    "normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "visualizer = AttributionVisualizer(\n",
    "    models=[model],\n",
    "    score_func=lambda o: torch.nn.functional.softmax(o, 1),\n",
    "    classes=get_classes(),\n",
    "    features=[\n",
    "        ImageFeature(\n",
    "            \"Photo\",\n",
    "            baseline_transforms=[baseline_func],\n",
    "            input_transforms=[normalize],\n",
    "        )\n",
    "    ],\n",
    "    dataset=formatted_data_iter(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912dbb29bd3743e7bf34b73363b3ee56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CaptumInsights(insights_config={'classes': ['अ', 'अं', 'अः', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ए', 'ऐ', 'ओ', 'औ', 'क',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41154f295b1b4bab87a2fe1a84a1093c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
